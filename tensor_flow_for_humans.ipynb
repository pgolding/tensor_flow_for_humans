{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Quick Intro (for Humans)\n",
    "\n",
    "In TF, data exists as tensors. These are computationally-optimized data types that represent matrices (or vectors).\n",
    "\n",
    "TF doesn't run your program like a standard Python program.\n",
    "\n",
    "It builds and then runs a mathematical representation, or **graph**. \n",
    "\n",
    "This is because, beneath the hood, TF is going to do the maths using an optimized engine that can map the calculations efficiently to a set of processors (e.g. GPU/TPU cores) running in parallel if possible (likely). \n",
    "\n",
    "In order to distribute the calculation across a set of processor nodes, TF needs a way to understand the topology of the calculation to begin with, hence the way that TF dictates a style of programming that declares the graph before running it.\n",
    "\n",
    "Therefore, TF runs the graph calculation within a Session().\n",
    "\n",
    "The following is a trivial example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'This is TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Declare TensorFlow object called tensor\n",
    "some_constant = tf.constant('This is TensorFlow!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(some_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to feed it actual data, versus constants (which still might be useful), we need to create inputs to the graph. These are like ports where we can inject data over time, keeping in mind that for a neural network to be useful, we are going to stream data into it (from a large data source, most likely).\n",
    "\n",
    "We need to be ready to stream data into TF and so we define inputs rather than input variables per se.\n",
    "\n",
    "In Python we do this:\n",
    "\n",
    "`x = some_data`\n",
    "\n",
    "In TF, we don't set the data, but rather the shape (and type) of the data. We do this using placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test String\n"
     ]
    }
   ],
   "source": [
    "# Some example placeholders - i.e. inputs for our graph\n",
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x,feed_dict={x: 'Test String', y: 123, z: 45.67})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, what?\n",
    "\n",
    "What was that `feed_dict` thing?\n",
    "\n",
    "That was us feeding some data to our placeholders.\n",
    "\n",
    "This `sess.run` is asking TF to give us the output of a node (`x`) in our graph. In this case, we are asking for the output of the node `x`. \n",
    "\n",
    "Clearly, we don't need the other inputs to compute `x` so they are redundant, but illustrative for this trivial example.\n",
    "\n",
    "We could do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Some example placeholders - i.e. inputs for our graph\n",
    "a = tf.placeholder(tf.int32)\n",
    "b = tf.placeholder(tf.int32)\n",
    "c = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(c,feed_dict={a: 2, b:2})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, of course, the beauty of TF is that it can handle vectors (of any dimension):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    output = sess.run(c,feed_dict={a: [1,1,1,1], b:[1,1,1,1]})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `+` here is a scalar addition happening \"bit-wise\" across the array. For a truly multi-dimensional array addition, we need to use `tf.add`, which we do here for a 4x2 array addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 2 2]\n",
      " [2 2 2 2]]\n"
     ]
    }
   ],
   "source": [
    "c = tf.add(a,b)\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(c,feed_dict={a: [[1,1,1,1],[1,1,1,1]], b:[[1,1,1,1],[1,1,1,1]]})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this isn't that useful if we have to write the values in our code.\n",
    "\n",
    "Ideally, we want to stream data into the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = [\n",
    "    [1, 1,],\n",
    "    [2, 2,],\n",
    "    [3, 3,],\n",
    "    [4, 4,],\n",
    "]\n",
    "slices = tf.data.Dataset.from_tensor_slices(some_data)\n",
    "next_slice = slices.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2]\n",
      "[4 4]\n",
      "[6 6]\n",
      "[8 8]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "      try:\n",
    "        val = sess.run(next_slice)\n",
    "        print(sess.run(c,feed_dict={a: val, b:val}))\n",
    "      except tf.errors.OutOfRangeError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Layers\n",
    "\n",
    "Thus far we've shown how we can setup inputs to a graph and feed data into them, including from a \"stream\".\n",
    "\n",
    "Of course, for this to be useful for a neural network, we need to feed data into a layer and do something useful.\n",
    "\n",
    "The most common operation in neural networks is calculating the linear combination of inputs, weights, and biases. As a reminder, we can write the output of the linear operation as\n",
    "\n",
    "![](linear-equation.gif)\n",
    "\n",
    "Here, $\\textbf{W}$ is a matrix of the weights connecting two layers. The output $\\textbf{y}$, the input $\\textbf{x}$, and the biases $\\textbf{b}$ are all vectors.\n",
    "\n",
    "Firstly, let's implement this ourselves using graph math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "w = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "y = tf.add(tf.matmul(x, w), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we had to use `tf.matmul()` here because we are multiplying matrices, not scalars.\n",
    "\n",
    "Now let's run this, but set our weights to 1s and our bias to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [8.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    sess.run(y, feed_dict={x:some_data, w:[[1],[1]],b:[[0]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is as expected.\n",
    "\n",
    "We are multiplying each input by 1 and adding 0.\n",
    "\n",
    "* `1*1 + 1*1 + 0 = 2`\n",
    "* `2*1 + 2*1 + 0 = 4`\n",
    "* `3*1 + 3*1 + 0 = 6`\n",
    "* `4*1 + 4*1 + 0 = 8`\n",
    "\n",
    "However, if we want to train our layer to give us a desired result (whatever that is going to be) then we need our weights and biases to be variables that we can updae on each iteration during training.\n",
    "\n",
    "Therefore, we use a different approach to initialize these variables using the `tf.Variable` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [8.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tf.Variable(tf.ones((2, 1)))\n",
    "b = tf.Variable(tf.zeros(1))\n",
    "y = tf.add(tf.matmul(x, w), b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    sess.run(y, feed_dict={x:some_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we don't know what the weights should be and so we need to initialize them to some values.\n",
    "\n",
    "For now, we will follow the heuristic that often works fine with training, which is to set the weights to some random (normalized) values and set the biases to all 0s. We are setting `seed=1` to control the random number generator so that we can get repeatable results later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67328054]\n",
      " [1.3465611 ]\n",
      " [2.0198417 ]\n",
      " [2.6931221 ]]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.truncated_normal((2, 1),seed=1))\n",
    "b = tf.Variable(tf.zeros(1))\n",
    "y = tf.add(tf.matmul(x, w), b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    output = sess.run(y, feed_dict={x:some_data})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Dense model\n",
    "\n",
    "Our desire to use a linear model of the type $\\textbf{y = Wx + b}$ is common enough that TF has a built-in graph primitive called `Dense`. It is a layer of perceptrons.\n",
    "\n",
    "Here we declare our model by declaring a `layer` of type `Dense`.\n",
    "\n",
    "We set `units=1` for our single output and here we override the default weights (usually random) so that we achieve the same function as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67328054]\n",
      " [1.3465611 ]\n",
      " [2.0198417 ]\n",
      " [2.6931221 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "linear_model = tf.layers.Dense(units=1,kernel_initializer=tf.truncated_normal_initializer(seed=1))\n",
    "y_dense = linear_model(x)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    dense_output = sess.run(y_dense, {x: some_data})\n",
    "    print(dense_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# were the two approaches the same?\n",
    "dense_output == output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we haven't mentioned yet is the function `global_variables_initializer()`\n",
    "\n",
    "This is to initialize the variables (i.e. weights and biases) before we can run the graph. Otherwise the weights and biases will be uninitialized (unset) and so the graph session will crash.\n",
    "\n",
    "Note that for initializing variables, there are a number of [initializers](https://www.tensorflow.org/api_docs/python/tf/initializers) that we could use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Now let's try our hand at a simple neural network with some training data.\n",
    "\n",
    "Now we will attempt to build a classifier using TF.\n",
    "\n",
    "To make things easy to understand and follow, I wrote a small [script](generate_shapes.ipynb) to produce some basic 28x28 pixel shapes, either cirles or squares. They are differing sizes and not fully formed - i.e. pixelated (mostly by image reduction). This will allow you play around with shape manipulation (e.g. try rotating or distoring the shapes) to see how well your network performs with noiser or cleaner data. The default data here is pretty clean.\n",
    "\n",
    "I have also resized everything to the \"canonical\" 28x28 that is commonly used for MNIST and similar datasets so that you are already mentally attuned to how the sizing of features (for those kinds of 2D images) works.\n",
    "\n",
    "The data is already prepared ready for TF. This means that each shape has been converted to a 784 Numpy array where the pixel values range from 0.1 to 0.9 (i.e. have been normalized). Moreover, I have also used the `LabelBinarizer`\n",
    "and `train_test_split` from `sklearn` to one-hot encode the labels and create the required training, validation and test data sets.\n",
    "\n",
    "But so we understand what's going on, let's look at a simple `Dense` layer to process one image.\n",
    "\n",
    "We are going to present each image as an example to the graph. To do that, we present **all 784 pixels at once**. Therefore, we immediately know that we need 784 inputs.\n",
    "\n",
    "Because our shapes are either circles or squares, we want to train the graph to recognize the presence of either one of these, which means we need two outputs.\n",
    "\n",
    "Let's load the data first, which was saved as a pickle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pickle_file = 'shape_data.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  train_features = pickle_data['train_dataset']\n",
    "  train_labels = pickle_data['train_labels']\n",
    "  valid_features = pickle_data['valid_dataset']\n",
    "  valid_labels = pickle_data['valid_labels']\n",
    "  test_features = pickle_data['test_dataset']\n",
    "  test_labels = pickle_data['test_labels']\n",
    "  del pickle_data  # Free up memory\n",
    "    \n",
    "\n",
    "# Make sure the TF graph is reset so we can inspect it later\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at a random selection of shapes to see what we're dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x122f96b00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x122fc2ef0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x122fed278>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x122ff3470>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x123034160>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11da40518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(1,6):\n",
    "    ax = fig.add_subplot(1, 6, i, xticks=[], yticks=[])\n",
    "    ax.imshow(np.reshape(train_features[random.randint(0,10000)],(28,28)), cmap='gray')\n",
    "#ax = fig.add_subplot(1, 6, 2, xticks=[], yticks=[])\n",
    "#ax.imshow(np.reshape(train_features[random.randint(0,10000)],(28,28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the squares are very well defined and the circles less so, but clearly they are very distinct. One can almost imagine how certain input patterns (like long run-lengths of black pixels) should create a higher probability of a `square==1` but we aren't really too interested in how it works for now (but this might be more interesting to inspect if trying out a Convolutional Neural Network later).\n",
    "\n",
    "Now let's set up a trivial dense layer with our 784 inputs and 2 outputs.\n",
    "\n",
    "We will set the weights to be 1s and leave the default biases as 0s. Without attempting to change these yet, this means we expect the layer to act as a simple accumulator (or adder) for the inputs. Both outputs will be identical.\n",
    "\n",
    "Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[738.8 738.8]]\n"
     ]
    }
   ],
   "source": [
    "input_shape = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "shape_classifier = tf.layers.Dense(units=2,kernel_initializer=tf.ones_initializer())\n",
    "y_shape = shape_classifier(input_shape)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    shape_output = sess.run(y_shape, {input_shape: [train_features[0]]})\n",
    "    print(shape_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we sum the values of the input shape pixel values, they should add up to the same number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738.8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we don't want the outputs to be merely the sum of the pixels. It is pretty obvious that this won't tell us anything much about the shape, except perhaps how much of the image has darker pixels (which would be a lower sum).\n",
    "\n",
    "First of all, let's get the output looking something like it's trying to predict the probability of either a circle or a square. To do that, we will use a softmax output.\n",
    "\n",
    "This looks at the values and adjusts them so they are similarly proportioned, except all add up to 1. Therefore the output of each is a kind of probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "# define our graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_shape = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "shape_classifier = tf.layers.Dense(units=2,kernel_initializer=tf.ones_initializer())\n",
    "y_shape = shape_classifier(input_shape)\n",
    "softmax = tf.nn.softmax(y_shape)\n",
    "\n",
    "#initialize our graph\n",
    "init = tf.global_variables_initializer()\n",
    "# run our graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    shape_output = sess.run(softmax, {input_shape: [train_features[0]]})\n",
    "    print(shape_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the way we've currently set up the graph, these answers are correct - i.e. there's a 50/50 chance of it being either shape. This is meaningless of course because both graphs are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset our graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Set the number of features - i.e. the pixels in each input shape\n",
    "features_count = 784\n",
    "# How many classes? Two shapes...\n",
    "classes_count = 2\n",
    "\n",
    "# Now set up our placeholder for the input shape (features)\n",
    "input_shape = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "\n",
    "# And now for the one-hot encoded labels\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# Now set up our layer of neurons (perceptrons)\n",
    "# We only need two units for the two type of shape (one-hot encoded)\n",
    "softmax = tf.layers.dense(input_shape, units=2,activation=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this time we told TF to set the layer's activation function to be `tf.nn.softmax` which is a callable function that performs the softmax distribution on the outputs for us. It just means we can skip the separate step that we had above.\n",
    "\n",
    "## Figuring out the Error (or Loss)\n",
    "\n",
    "The cross-entropy of a neural network is fancy name for a measure of how well it's classifying. \n",
    "In layman's terms, it's the product of all the `softmax` probabilities that the network predicts weighted by the actual values (`labels`) to reward correct predictions and punish bad ones. \n",
    "\n",
    "For computational efficiency (mostly precision), we want to avoid products and use summation. We can do this by taking the logs of the probabilities and then summing the logs.\n",
    "\n",
    "Fortunately, this function is easy to compute with TF using [`reduce_sum`](https://www.tensorflow.org/api_docs/python/tf/reduce_sum) which sums across all the input tensor elements.\n",
    "\n",
    "Of course, we then want to know the average (mean) of the sums so that we can see overall how well our graph is doing. We can call this the `loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(softmax), axis=1)\n",
    "\n",
    "# Training loss\n",
    "loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to Measure Accuracy\n",
    "\n",
    "Once we set our graph in motion by streaming the inputs in a `Session.run()` we want to keep track of how well it's performing. The loss is one measure of course, but is a metric and not the accuracy per se. \n",
    "\n",
    "For the accuracy, we will want to first see if our prediction was correct.\n",
    "\n",
    "We can't simply use a python test like `softmax == label` because we are dealing with tensors (i.e. vectors) and what we want to know is whether the highest probability output (in this case of the two possible outputs) aligns with the `1` in the softmax vector.\n",
    "\n",
    "To do this, we could see which of the softmax outputs is the highest, as this gives us the graph's prediction and then which of the label's values is the highest. If these align (i.e. the maximums) then we can say that the prediction is correct.\n",
    "\n",
    "In other words, say softmax is `[0.1, 0.9]`, then the max value is at `index=1` in the tensor.\n",
    "\n",
    "Now let's say that the label is `[0.0, 1.0]` then we see that the max is also at `index=1` (or aligned in terms of one-hot encoding) and so we can say that this is a correct prediction.\n",
    "\n",
    "TF gives us a function called [`argmax`](https://www.tensorflow.org/api_docs/python/tf/arg_max) to calculate which of the indexes has the maxium value. We then calculate if they are aligned - i.e. equal.\n",
    "\n",
    "We then want to add up all the right answers and divide by the total number of predictions to get a running average. We can't just compute an average of the prediction test (`tf.equal`) because the answer is `boolean`. We therefore convert this to a floating point value using `tf.cast`\n",
    "\n",
    "Don't forget that this code below is **not** going to run now. It is merely setting up part of the graph. So long as we feed it with the correct data streams (`softmax, labels`) during a session, it will compute the accuracy for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine if the predictions are correct\n",
    "is_correct = tf.equal(tf.argmax(softmax, 1), tf.argmax(labels, 1))\n",
    "# # Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start to build our trainable graph, we need to understand a few things about TF. \n",
    "\n",
    "It makes some assumptions. One of them is that the `Dense` layer has two tensors that are variables and therefore trainable. We can inspect [trainable tensors](https://www.tensorflow.org/api_docs/python/tf/trainable_variables) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(784, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation\n",
    "\n",
    "This is what we expect because we can see that these tensors are the kernel (i.e. weights) and biases for our `Dense` layer. We can see here that without us doing anything, TF has already assigned a tensor for the weights (`kernel`) and a tensor for the biases (`bias`).\n",
    "\n",
    "This is important because now we are getting to the crux of the graph, which is the ability for it to learn.\n",
    "\n",
    "How is this going to happen?\n",
    "\n",
    "As you hopefully know, the learning is a process of tweaking the weights and biases until a set is found that minimizes the overall error, or what we have called `loss` above.\n",
    "\n",
    "In this example, we will use Mini-Batch Gradient Descent to try and find a minimum for `loss` as a function of the weights and biases. This is done by calculating the gradient of that function and then adjusting the weights in the direction of downward slope (hopefully towards a minimum) for each batch of training shapes. The optimization is via the process of back propagation.\n",
    "\n",
    "Rather beautifully, TF can do all this for us so that we don't have to figure out how to differentiate the activation function and so on. We simply set up a training optimizer.\n",
    "\n",
    "How fast we attempt to climb down the slope is set by the step size, or what we call the `learning rate`, so we have to set this value. Of course, there is no way of knowing in advance what to set it to, so we will take a guess initially. But you will notice by playing with it that the rate can dramatically affect the results, including getting no useful results at all (due to overshoot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play around with this later to see what it does\n",
    "learning_rate = 0.05\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Training\n",
    "\n",
    "To train our network, we need to repeatedly feed the training vectors into the graph and run backprop to calculate the new weights using the Stochastic Gradient Descent optimizer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95000 training samples; 743 batches of size:128\n"
     ]
    }
   ],
   "source": [
    "#initialize our graph - i.e. set up the Dense layer (e.g. the weights/biases)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "train_feed_dict = {input_shape: train_features, labels: train_labels}\n",
    "valid_feed_dict = {input_shape: valid_features, labels: valid_labels}\n",
    "test_feed_dict = {input_shape: test_features, labels: test_labels}\n",
    "\n",
    "# How many samples we feed through the graph before we update the model\n",
    "# Pay with this value later\n",
    "batch_size = 128\n",
    "# How many times we will train the network (and see how that improves our model)\n",
    "# Pay with this value later\n",
    "n_epochs = 4 \n",
    "\n",
    "# The validation accuracy - i.e. how well do our validation samples do during training, per epoch\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "batch_logging_sizes = 64\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "print('{} training samples; {} batches of size:{}'.format(len(train_features),batch_count,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 with validation accuracy 0.0: 100%|██████████| 743/743 [00:02<00:00, 356.97batches/s]\n",
      "Epoch 2/4 with validation accuracy 0.8849999904632568: 100%|██████████| 743/743 [00:02<00:00, 359.22batches/s]\n",
      "Epoch 3/4 with validation accuracy 1.0: 100%|██████████| 743/743 [00:02<00:00, 361.27batches/s]\n",
      "Epoch 4/4 with validation accuracy 1.0: 100%|██████████| 743/743 [00:02<00:00, 352.82batches/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Loss')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1231908d0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(64, 3072)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Accuracy')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1231b9ef0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x123190908>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(64, 3072)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1231cdba8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123160b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    # figure out how many training vectors we need per batch\n",
    "    # Do some rounding to an integer\n",
    "    \n",
    "\n",
    "    for ith_epoch in range(n_epochs):\n",
    "        \n",
    "        # Progress bar - so we get a progress bar using the Python TQDM lib\n",
    "        # It's just a wrapper for our range\n",
    "        batch_progress = tqdm(range(batch_count), desc='Epoch {}/{} with validation accuracy {}'.\n",
    "                              format(ith_epoch+1, n_epochs,validation_accuracy), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for ith_batch in batch_progress:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = ith_batch*batch_size # our pointer (index) into the entire feature set\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer and get loss for batch_size of features\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={input_shape: batch_features, labels: batch_labels})\n",
    "\n",
    "            # Log accuracy every log_batch_step batches - no need to calculate each loop\n",
    "            # But this has nothing to do with the training, just the monitoring of performance\n",
    "            if not ith_batch % batch_logging_sizes:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "                # Log batches so that we can plot them\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(batch_logging_sizes + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "\n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'b')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it converged fairly quickly on a highly accurate model that is able to predict shapes all of the time. This is to be expected given the highly dissimilar (orthogonal) nature of the training data and the amount of it. We contrived this example to make things easy (and mostly instructive) for ourselves as an entry point into the world of TF.\n",
    "\n",
    "# Test Accuracy\n",
    "\n",
    "In our original dataset, we generated an independent set of shapes that the network hasn't seen before during training. (Well, given the way we generate shapes, it is highly likely that the network **has** seen these shapes, but let's ignore that for this lesson.)\n",
    "\n",
    "Now we re-run the network, but with the test data and don't bother calculating `loss` because we are no longer optimizing, but rather presenting data to see what the network predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4: 100%|██████████| 743/743 [00:00<00:00, 1723.27batches/s]\n",
      "Epoch 2/4: 100%|██████████| 743/743 [00:00<00:00, 1785.34batches/s]\n",
      "Epoch 3/4: 100%|██████████| 743/743 [00:00<00:00, 1663.48batches/s]\n",
      "Epoch 4/4: 100%|██████████| 743/743 [00:00<00:00, 1743.27batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The accuracy measured against the test set\n",
    "test_accuracy = 0.0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for ith_epoch in range(n_epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_prog = tqdm(range(batch_count), desc='Epoch {}/{}'.format(ith_epoch+1, n_epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for ith_batch in batches_prog:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = ith_batch*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer\n",
    "            _ = session.run(optimizer, feed_dict={input_shape: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Check accuracy against Test data\n",
    "        test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "\n",
    "print('Test Accuracy:{}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
